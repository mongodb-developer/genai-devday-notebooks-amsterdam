{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Lab Documentation and Solutions](https://img.shields.io/badge/Lab%20Documentation%20and%20Solutions-purple)](https://mongodb-developer.github.io/ai-agents-lab/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RM8rg08YhqZe"
      },
      "source": [
        "# Step 1: Setup prerequisites"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from pymongo import MongoClient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# If you are using your own MongoDB Atlas cluster, use the connection string for your cluster here\n",
        "MONGODB_URI = os.environ.get(\"MONGODB_URI\")\n",
        "# Initialize a MongoDB Python client\n",
        "mongodb_client = MongoClient(MONGODB_URI)\n",
        "# Check the connection to the server\n",
        "mongodb_client.admin.command(\"ping\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Pick an LLM provider of your choice below**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "SERVERLESS_URL = os.environ.get(\"SERVERLESS_URL\")\n",
        "# Can be one of \"aws\", \"google\" or \"microsoft\"\n",
        "LLM_PROVIDER = \"aws\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUf3jtFzO4-V"
      },
      "source": [
        "# Step 2: Import data into MongoDB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Do not change the values assigned to the variables below**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#  Database name\n",
        "DB_NAME = \"mongodb_genai_devday_agents\"\n",
        "# Name of the collection with full documents- used for summarization\n",
        "FULL_COLLECTION_NAME = \"mongodb_docs\"\n",
        "# Name of the collection for vector search- used for Q&A\n",
        "VS_COLLECTION_NAME = \"mongodb_docs_embeddings\"\n",
        "# Name of the vector search index\n",
        "VS_INDEX_NAME = \"vector_index\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Connect to the `VS_COLLECTION_NAME` collection.\n",
        "vs_collection = mongodb_client[DB_NAME][VS_COLLECTION_NAME]\n",
        "# Connect to the `FULL_COLLECTION_NAME` collection.\n",
        "full_collection = mongodb_client[DB_NAME][FULL_COLLECTION_NAME]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Insert a dataset of MongoDB docs with embeddings into the `VS_COLLECTION_NAME` collection\n",
        "with open(f\"../data/{VS_COLLECTION_NAME}.json\", \"r\") as data_file:\n",
        "    json_data = data_file.read()\n",
        "\n",
        "data = json.loads(json_data)\n",
        "\n",
        "print(f\"Deleting existing documents from the {VS_COLLECTION_NAME} collection.\")\n",
        "vs_collection.delete_many({})\n",
        "vs_collection.insert_many(data)\n",
        "print(\n",
        "    f\"{vs_collection.count_documents({})} documents ingested into the {VS_COLLECTION_NAME} collection.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Insert a dataset of MongoDB documentation pages into the `FULL_COLLECTION_NAME` collection\n",
        "with open(f\"../data/{FULL_COLLECTION_NAME}.json\", \"r\") as data_file:\n",
        "    json_data = data_file.read()\n",
        "\n",
        "data = json.loads(json_data)\n",
        "\n",
        "print(f\"Deleting existing documents from the {FULL_COLLECTION_NAME} collection.\")\n",
        "full_collection.delete_many({})\n",
        "full_collection.insert_many(data)\n",
        "print(\n",
        "    f\"{full_collection.count_documents({})} documents ingested into the {FULL_COLLECTION_NAME} collection.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Step 3: Create a vector search index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utils import create_index, check_index_ready"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create vector index definition specifying:\n",
        "# path: Path to the embeddings field\n",
        "# numDimensions: Number of embedding dimensions- depends on the embedding model used\n",
        "# similarity: Similarity metric. One of cosine, euclidean, dotProduct.\n",
        "model = {\n",
        "    \"name\": VS_INDEX_NAME,\n",
        "    \"type\": \"vectorSearch\",\n",
        "    \"definition\": {\n",
        "        \"fields\": [\n",
        "            {\n",
        "                \"type\": \"vector\",\n",
        "                \"path\": \"embedding\",\n",
        "                \"numDimensions\": 384,\n",
        "                \"similarity\": \"cosine\",\n",
        "            }\n",
        "        ]\n",
        "    },\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ðŸ“š Refer to the `utils.py` script under `notebooks/utils`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use the `create_index` function from the `utils` module to create a vector search index with the above definition for the `vs_collection` collection\n",
        "<CODE_BLOCK_1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use the `check_index_ready` function from the `utils` module to verify that the index was created and is in READY status before proceeding\n",
        "check_index_ready(vs_collection, VS_INDEX_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZfheX5FiIhU"
      },
      "source": [
        "# Step 4: Create agent tools\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# You may see a warning upon running this cell. You can ignore it.\n",
        "from langchain.agents import tool\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from typing import List"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Vector Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the `gte-small` model using the Sentence Transformers library\n",
        "embedding_model = SentenceTransformer(\"thenlper/gte-small\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ðŸ“š https://huggingface.co/thenlper/gte-small#usage (See \"Use with sentence-transformers\" under Usage)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define a function that takes a piece of text (`text`) as input, embeds it using the `embedding_model` instantiated above and returns the embedding as a list\n",
        "# An array can be converted to a list using the `tolist()` method\n",
        "def get_embedding(text: str) -> List[float]:\n",
        "    \"\"\"\n",
        "    Generate the embedding for a piece of text.\n",
        "\n",
        "    Args:\n",
        "        text (str): Text to embed.\n",
        "\n",
        "    Returns:\n",
        "        List[float]: Embedding of the text as a list.\n",
        "    \"\"\"\n",
        "    embedding = <CODE_BLOCK_2>\n",
        "    return embedding.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ðŸ“š https://www.mongodb.com/docs/atlas/atlas-vector-search/vector-search-stage/#ann-examples (Refer to the \"Basic Example\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define a tool to retrieve relevant documents for a user query using vector search\n",
        "@tool\n",
        "def get_information_for_question_answering(user_query: str) -> str:\n",
        "    \"\"\"\n",
        "    Retrieve information using vector search to answer a user query.\n",
        "\n",
        "    Args:\n",
        "    user_query (str): The user's query string.\n",
        "\n",
        "    Returns:\n",
        "    str: The retrieved information formatted as a string.\n",
        "    \"\"\"\n",
        "\n",
        "    # Generate embedding for the `user_query` using the `get_embedding` function defined above\n",
        "    query_embedding = <CODE_BLOCK_33>\n",
        "\n",
        "    # Define an aggregation pipeline consisting of a $vectorSearch stage, followed by a $project stage\n",
        "    # Set the number of candidates to 150 and only return the top 5 documents from the vector search\n",
        "    # In the $project stage, exclude the `_id` field and include only the `body` field and `vectorSearchScore`\n",
        "    # NOTE: Use variables defined previously for the `index`, `queryVector` and `path` fields in the $vectorSearch stage\n",
        "    pipeline = <CODE_BLOCK_4>\n",
        "\n",
        "    # Execute the aggregation `pipeline` against the `vs_collection` collection and store the results in `results`\n",
        "    results = <CODE_BLOCK_5>\n",
        "    # Concatenate the results into a string\n",
        "    context = \"\\n\\n\".join([doc.get(\"body\") for doc in results])\n",
        "    return context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get page content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ðŸ“š https://www.mongodb.com/docs/manual/reference/method/db.collection.findOne/#return-all-but-the-excluded-fields"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define a tool to retrieve the content of a documentation page for summarization\n",
        "@tool\n",
        "def get_page_content_for_summarization(user_query: str) -> str:\n",
        "    \"\"\"\n",
        "    Retrieve page content based on provided title.\n",
        "\n",
        "    Args:\n",
        "    user_query (str): The user's query string i.e. title of the documentation page.\n",
        "\n",
        "    Returns:\n",
        "    str: The content of the page.\n",
        "    \"\"\"\n",
        "    # Query the documents where the `title` field is equal to the `user_query`\n",
        "    query = <CODE_BLOCK_6>\n",
        "    # Only return the `body` field from the retrieved documents.\n",
        "    # NOTE: Set fields to include to 1, those to exclude to 0. `_id` is included by default, so exclude that.\n",
        "    projection = <CODE_BLOCK_7>\n",
        "    # Use the `query` and `projection` with the `find_one` method\n",
        "    # to get the `body` of the document with `title` equal to the `user_query` from the `full_collection` collection\n",
        "    document = <CODE_BLOCK_8>\n",
        "    if document:\n",
        "        return document[\"body\"]\n",
        "    else:\n",
        "        return \"Document not found\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create the list of tools\n",
        "tools = [\n",
        "    get_information_for_question_answering,\n",
        "    get_page_content_for_summarization,\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test out the tools\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test out the `get_information_for_question_answering` tool with the query \"What are some best practices for data backups in MongoDB?\"\n",
        "# You should see a non-empty response\n",
        "get_information_for_question_answering.invoke(\n",
        "    \"What are some best practices for data backups in MongoDB?\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test out the `get_page_content_for_summarization` tool with page title \"Create a MongoDB Deployment\"\n",
        "# You should see a non-empty response\n",
        "get_page_content_for_summarization.invoke(\"Create a MongoDB Deployment\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Step 5: Define graph state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Annotated\n",
        "from langgraph.graph.message import add_messages\n",
        "from typing_extensions import TypedDict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the graph state\n",
        "# We are only tracking chat messages but you can track other attributes as well\n",
        "class GraphState(TypedDict):\n",
        "    messages: Annotated[list, add_messages]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Step 6: Instantiate the LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.load import load\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Obtain the Langchain LLM object from our serverless endpoint\n",
        "llm_dict = requests.post(\n",
        "    url=SERVERLESS_URL, json={\"task\": \"get_llm\", \"data\": LLM_PROVIDER}\n",
        ").json()\n",
        "llm = load(llm_dict[\"llm\"], secrets_map=llm_dict[\"secrets_map\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a Chain-of-Thought (CoT) prompt template for the agent.\n",
        "# This includes a system prompt with a placeholder for tool names, and a placeholder for messages i.e. user queries and assistant responses\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"You are a helpful AI assistant.\"\n",
        "            \" You are provided with tools to answer questions and summarize technical documentation related to MongoDB.\"\n",
        "            \" Think step-by-step and use these tools to get the information required to answer the user query.\"\n",
        "            \" Do not re-run tools unless absolutely necessary.\"\n",
        "            \" If you are not able to get enough information using the tools, reply with I DON'T KNOW.\"\n",
        "            \" You have access to the following tools: {tool_names}.\"\n",
        "        ),\n",
        "        MessagesPlaceholder(variable_name=\"messages\"),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fill in the prompt template with the tool names\n",
        "prompt = prompt.partial(tool_names=\", \".join([tool.name for tool in tools]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Step 7: Define a ReAct Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "agent = create_react_agent(\n",
        "    model=<CODE_BLOCK_9>,  \n",
        "    tools=<CODE_BLOCK_10>,\n",
        "    prompt=<CODE_BLOCK_11>\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ðŸ“š https://langchain-ai.github.io/langgraph/agents/agents/#2-create-an-agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utils import visualize_graph\n",
        "# Visualize the graph\n",
        "visualize_graph(agent)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Step 8: Run the Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Stream outputs from the graph as they pass through its nodes\n",
        "def execute_graph(user_input: str) -> None:\n",
        "    \"\"\"\n",
        "    Stream outputs from the graph\n",
        "\n",
        "    Args:\n",
        "        user_input (str): User query string\n",
        "    \"\"\"\n",
        "    # Add user input to the messages attribute of the graph state\n",
        "    # The role of the message should be \"user\" and content should be `user_input`\n",
        "    input = {\"messages\": [(\"user\", user_input)]}\n",
        "    # Pass input to the graph and stream the outputs\n",
        "    for output in app.stream(input):\n",
        "        for key, value in output.items():\n",
        "            print(f\"Node {key}:\")\n",
        "            print(value)\n",
        "    print(\"---FINAL ANSWER---\")\n",
        "    print(value[\"messages\"][-1].content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test the graph execution to view end-to-end flow\n",
        "execute_graph(\"What are some best practices for data backups in MongoDB?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Step 9: Add memory to the agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langgraph.checkpoint.mongodb import MongoDBSaver"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize a MongoDB checkpointer\n",
        "checkpointer = MongoDBSaver(mongodb_client)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Instantiate the agent with the checkpointer\n",
        "agent = create_react_agent(\n",
        "    model=llm,  \n",
        "    tools=tools,\n",
        "    prompt=prompt,\n",
        "    checkpointer=checkpointer\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ðŸ“š https://langchain-ai.github.io/langgraph/concepts/persistence/#threads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def execute_graph(thread_id: str, user_input: str) -> None:\n",
        "    \"\"\"\n",
        "    Stream outputs from the graph\n",
        "\n",
        "    Args:\n",
        "        thread_id (str): Thread ID for the checkpointer\n",
        "        user_input (str): User query string\n",
        "    \"\"\"\n",
        "    # Add user input to the messages attribute of the graph state\n",
        "    # The role of the message should be \"user\" and content should be `user_input`\n",
        "    input = {\"messages\": [(\"user\", user_input)]}\n",
        "    # Define a config containing the thread ID\n",
        "    config = <CODE_BLOCK_12>\n",
        "    # Pass `input` and `config` to the graph and stream outputs\n",
        "    for output in agent.stream(input, config):\n",
        "        for key, value in output.items():\n",
        "            print(f\"Node {key}:\")\n",
        "            print(value)\n",
        "    print(\"---FINAL ANSWER---\")\n",
        "    print(value[\"messages\"][-1].content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test graph execution with thread ID\n",
        "execute_graph(\n",
        "    thread_id=\"1\",\n",
        "    user_input=\"What are some best practices for data backups in MongoDB?\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Follow-up question to ensure message history works\n",
        "execute_graph(\n",
        "    thread_id=\"1\",\n",
        "    user_input=\"What did I just ask you?\",\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "state": {}
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
